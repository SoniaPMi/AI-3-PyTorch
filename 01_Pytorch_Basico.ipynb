{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "01-Pytorch-Basico.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoniaPMi/AI-3-PyTorch/blob/main/01_Pytorch_Basico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVBv0eq8108q"
      },
      "source": [
        "![IDAL](https://i.imgur.com/tIKXIG1.jpg)  \n",
        "\n",
        "#**Máster en Inteligencia Artificial Avanzada y Aplicada:  IA^3**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZZRnhKHlmxp"
      },
      "source": [
        "#<strong><center>Tensores en Pytorch</center></strong>\n",
        "\n",
        "# Tensores y operaciones básicas\n",
        "Esta sección cubre: \n",
        "* Convertir arrays NumPy a tensores PyTorch \n",
        "* Crear tensores desde cero\n",
        "\n",
        "## Realizamos la importación de modulos habitual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lcxzjoFlmxr"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJ-Bsrxlmxs"
      },
      "source": [
        "Comprobamos version de PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5l1VMiwlmxt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05cb6336-c09a-4266-ff34-fc0b01599787"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKisj_jKlmxw"
      },
      "source": [
        "## Conversión de arrays NumPy a tensores PyTorch\n",
        "Un <a href='https://pytorch.org/docs/stable/tensors.html'><strong><tt>torch.Tensor</tt></strong></a> es una matriz multi-dimensional que contiene elementos de un mismo tipo de datos.<br>\n",
        "Los cálculos entre tensores solo se pueden dar si los tensores son del mismo dtype.<br>\n",
        "En pytorch, los tensores son usados también como sustitución de Numpy para usar la potencia y posibilidades de GPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLAllnXLlmxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec870164-d3b0-4238-9c7d-924296832226"
      },
      "source": [
        "arr = np.array([1,2,3,4,5])\n",
        "print(arr)\n",
        "print(arr.dtype)\n",
        "print(type(arr))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5]\n",
            "int64\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz1OWfvElmxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f4d374-20da-4cb2-cfca-4387ea31e001"
      },
      "source": [
        "x = torch.from_numpy(arr)\n",
        "# Equivalente a x = torch.as_tensor(arr)\n",
        "\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv-ceY6olmx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b01b2b-fc54-4eb0-f0a3-73ce1d29ddd7"
      },
      "source": [
        "# Imprimimos el tipo de datos que contiene el tensor\n",
        "print(x.dtype)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9q-4ggclmx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b93b706-f8be-4bbe-e842-f2ab12ccf452"
      },
      "source": [
        "# Imprimimos en tipo de objeto que es el tensor\n",
        "print(type(x))\n",
        "print(x.type()) # más especifico!"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEuEvx7slmx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bf38af-f82e-4c1e-e7e6-b978b7614bf0"
      },
      "source": [
        "arr2 = np.arange(0.,12.).reshape(4,3)\n",
        "print(arr2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  1.  2.]\n",
            " [ 3.  4.  5.]\n",
            " [ 6.  7.  8.]\n",
            " [ 9. 10. 11.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqL1ZSgZlmx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d207ec2a-440f-46a7-e4f6-f54c7a0aefca"
      },
      "source": [
        "x2 = torch.from_numpy(arr2)\n",
        "print(x2)\n",
        "print(x2.type())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.]], dtype=torch.float64)\n",
            "torch.DoubleTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKN8-qCRlmx4"
      },
      "source": [
        "Aquí <tt>torch.DoubleTensor</tt> se refiere a datos \"64-bit floating point\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTvOGNcMlmx4"
      },
      "source": [
        "## Tipos de datos en Tensores\n",
        "Puedes consultar aquí en detalle los <a href='https://pytorch.org/docs/stable/tensors.html'>tipos de datos en Tensores</a>\n",
        "<table style=\"display: inline-block\">\n",
        "<tr><th>TYPE</th><th>NAME</th><th>EQUIVALENT</th><th>TENSOR TYPE</th></tr>\n",
        "<tr><td>32-bit integer (signed)</td><td>torch.int32</td><td>torch.int</td><td>IntTensor</td></tr>\n",
        "<tr><td>64-bit integer (signed)</td><td>torch.int64</td><td>torch.long</td><td>LongTensor</td></tr>\n",
        "<tr><td>16-bit integer (signed)</td><td>torch.int16</td><td>torch.short</td><td>ShortTensor</td></tr>\n",
        "<tr><td>32-bit floating point</td><td>torch.float32</td><td>torch.float</td><td>FloatTensor</td></tr>\n",
        "<tr><td>64-bit floating point</td><td>torch.float64</td><td>torch.double</td><td>DoubleTensor</td></tr>\n",
        "<tr><td>16-bit floating point</td><td>torch.float16</td><td>torch.half</td><td>HalfTensor</td></tr>\n",
        "<tr><td>8-bit integer (signed)</td><td>torch.int8</td><td></td><td>CharTensor</td></tr>\n",
        "<tr><td>8-bit integer (unsigned)</td><td>torch.uint8</td><td></td><td>ByteTensor</td></tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNdPMJrYlmx5"
      },
      "source": [
        "## Copiar vs. compartir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDwABI40lmx6"
      },
      "source": [
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.from_numpy'><strong><tt>torch.from_numpy()</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.as_tensor'><strong><tt>torch.as_tensor()</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.tensor'><strong><tt>torch.tensor()</tt></strong></a><br>\n",
        "\n",
        "Hay diferentes funciones disponibles para <a href='https://pytorch.org/docs/stable/torch.html#creation-ops'>crear tensores</a>. Cuando usamos <a href='https://pytorch.org/docs/stable/torch.html#torch.from_numpy'><strong><tt>torch.from_numpy()</tt></strong></a> y <a href='https://pytorch.org/docs/stable/torch.html#torch.as_tensor'><strong><tt>torch.as_tensor()</tt></strong></a>, el tensor PyTorch y el array origen NumPy comparten la misma memoria. Esto significa que el cambio en uno afecta al otro. Sin embargo, la función <a href='https://pytorch.org/docs/stable/torch.html#torch.tensor'><strong><tt>torch.tensor()</tt></strong></a> siempre hace una copia nueva del tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBsc-04elmx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11403ce-1be6-4ba8-c309-6b764e8843c6"
      },
      "source": [
        "# torch.from_numpy()\n",
        "arr = np.arange(0,5)\n",
        "t = torch.from_numpy(arr)\n",
        "print(t)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2jedzPSlmx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f20216-2ea8-42a9-bb6d-ea3cbdbc255e"
      },
      "source": [
        "arr[2]=77\n",
        "print(t)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  1, 77,  3,  4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-kMxUIelmx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042a9297-273e-4222-e299-c0ce1e4bfbf0"
      },
      "source": [
        "# torch.tensor()\n",
        "arr = np.arange(0,5)\n",
        "t = torch.tensor(arr)\n",
        "print(t)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHQv4cSFlmx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2772afad-5a92-40a2-a48e-62eac23bd679"
      },
      "source": [
        "arr[2]=77 #el tensor no se modifica\n",
        "print(t)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsIjF8Yylmx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6d2a2a-ea5c-461d-a6c3-09b03c9470fb"
      },
      "source": [
        "arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1, 77,  3,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdlBo5y8lmx-"
      },
      "source": [
        "## Clases constructoras\n",
        "<a href='https://pytorch.org/docs/stable/tensors.html'><strong><tt>torch.Tensor()</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/tensors.html'><strong><tt>torch.FloatTensor()</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/tensors.html'><strong><tt>torch.LongTensor()</tt></strong></a>, etc.<br>\n",
        "\n",
        "Hay una diferencia entre emplear la función predeterminada <font color=black><tt>torch.tensor(data)</tt></font> y la clase constructora <font color=black><tt>torch.Tensor(data)</tt></font>.<br>\n",
        "La función predeterminada adjudica el tipo de datos de los datos suministrados o del argumento \"dtype\" que se le pase. <br>\n",
        "La clase constructora <tt>torch.Tensor()</tt> es simplemente un alias para <tt>torch.FloatTensor(data)</tt>. Consideremos lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCpyPohZlmx_"
      },
      "source": [
        "data = np.array([1,2,3])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I2-20qAlmx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e906bbf9-70b2-4f85-fb0f-4e4ea5481033"
      },
      "source": [
        "a = torch.Tensor(data)  # Equivalente a cc = torch.FloatTensor(data)\n",
        "print(a, a.type())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.]) torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntt_2H8almyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3496fb-8264-4e32-8ff4-707855df30af"
      },
      "source": [
        "b = torch.tensor(data)\n",
        "print(b, b.type())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC_-JDn6lmyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad473d1-3ce3-4fd9-db4c-b77100e31cf7"
      },
      "source": [
        "c = torch.LongTensor(data)\n",
        "print(c, c.type())\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNLmqWw8lmyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a37313-5128-45a1-bb07-51f0cf54d13a"
      },
      "source": [
        "a.dtype"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maM0xiUmsMc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4070a3-823f-46af-c269-b771d158e063"
      },
      "source": [
        "b.dtype"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ctXnQW_yDt",
        "outputId": "fb7414d7-802f-4728-f064-ee0e00172038"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW-pM_L0lmyE"
      },
      "source": [
        "## Creando tensores desde cero\n",
        "### Inicializando tensores con <tt>.empty()</tt>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.empty'>\n",
        "# <strong><tt>torch.empty()</tt></strong></a> devuelve un tensor <em>no inicializado</em>. Esencialmente un bloque de memoria es reservado de acerdo al tamaño del tensor, y ningún valor ya dispuesto en dicho bloque es retornado. Es similar al comportamiento de <tt>numpy.empty()</tt>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbJnyT4lmyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a54f31-b3b4-4145-aea1-65de434c8cfb"
      },
      "source": [
        "x = torch.empty(4, 3)\n",
        "print(x)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.5947e+08, 3.0896e-41, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "        [4.5828e+30, 1.2121e+04, 7.1846e+22]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpuN0YUalmyF"
      },
      "source": [
        "### Inicialización de tensores con <tt>.zeros()</tt> and <tt>.ones()</tt>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.zeros'><strong><tt>torch.zeros(size)</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.ones'><strong><tt>torch.ones(size)</tt></strong></a><br>\n",
        "Es aconsejable pasar como argumento el dtype que queremos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfOEQgcxlmyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c422b9c4-582d-4dbf-d18b-021211112af1"
      },
      "source": [
        "x = torch.zeros(4, 3, dtype=torch.int64)\n",
        "print(x)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx = torch.ones(4, 3, dtype=torch.int64)\n",
        "print(xx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drTs48gOB77w",
        "outputId": "924f9a19-d6d4-4dcc-abb5-05d07832b338"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoKASDHSlmyG"
      },
      "source": [
        "### Tensores desde rangos\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.arange'><strong><tt>torch.arange(start,end,step)</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.linspace'><strong><tt>torch.linspace(start,end,steps)</tt></strong></a><br>\n",
        "\n",
        "Nota: con <tt>.arange()</tt>, <tt>end</tt> es exclusivo, mientras que con <tt>linspace()</tt>, <tt>end</tt> es inclusivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbZllptQlmyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f2dd63-37d7-48ef-f38a-00a1e4b7d83d"
      },
      "source": [
        "x = torch.arange(0,18,2).reshape(3,3)\n",
        "print(x)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  2,  4],\n",
            "        [ 6,  8, 10],\n",
            "        [12, 14, 16]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f9iYa6AlmyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd30062-bfcd-465b-8966-a7e24f13f146"
      },
      "source": [
        "x = torch.linspace(0,18,12).reshape(3,4)\n",
        "print(x)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  1.6364,  3.2727,  4.9091],\n",
            "        [ 6.5455,  8.1818,  9.8182, 11.4545],\n",
            "        [13.0909, 14.7273, 16.3636, 18.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaifWyUplmyI"
      },
      "source": [
        "### Tensores desde datos\n",
        "<tt>torch.tensor()</tt> adjudica el tipo de dato (dtype) basado en los datos suministrados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h2i7SsilmyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67031ad4-ec2f-49d7-db9b-f4cc5799871a"
      },
      "source": [
        "x = torch.tensor([1, 2, 3, 4])\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "print(x.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n",
            "torch.int64\n",
            "torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U0eMQPRlmyJ"
      },
      "source": [
        "Alternativamente puedes establecer el tipo de dato segun el método de tensor empleado. Para listado de los tipos de tensores ver https://pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY21d8B8lmyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0be5f13-9469-4b9f-a643-8496788a0b7b"
      },
      "source": [
        "x = torch.FloatTensor([5,6,7])\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "print(x.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 6., 7.])\n",
            "torch.float32\n",
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyoTA243lmyL"
      },
      "source": [
        "También puedes pasar el tipo de dato como un argumento. Para una lista de tipos de datos dtypes visitar https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOqa7_V9lmyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a151ad8c-67e3-41a1-9abd-9cc3ee27fdee"
      },
      "source": [
        "x = torch.tensor([8,9,-3], dtype=torch.int)\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "print(x.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8,  9, -3], dtype=torch.int32)\n",
            "torch.int32\n",
            "torch.IntTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH2Fm0oKlmyM"
      },
      "source": [
        "### Cambiando el dtype de tensores existentes\n",
        "\n",
        "Para cambiar el dtype no debes usar <tt>x = torch.tensor(x, dtype=torch.type)</tt> ya que dará un error de intento inapropiado de clonado de tensor.<br>\n",
        "En su lugar se debe emplear el metodo <tt>.type()</tt>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1GoayN_lmyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6544840f-7d9d-4d3c-8ffc-23a5e28f9597"
      },
      "source": [
        "print('Old:', x.type())\n",
        "\n",
        "x = x.type(torch.int64)\n",
        "\n",
        "print('New:', x.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old: torch.IntTensor\n",
            "New: torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afFlesoolmyN"
      },
      "source": [
        "### Tensores de números aleatorios\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.rand'><strong><tt>torch.rand(size)</tt></strong></a> devuelve muestras aleaorias con una distribución uniforme entre [0, 1]<br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.randn'><strong><tt>torch.randn(size)</tt></strong></a> devuelve muestras con una distribución \"standard normal\" con [σ = 1]<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;A diferencia de <tt>rand</tt> que es uniforme, valores cercanos a cero son más probables a aparecer en este tipo de generación.<br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.randint'><strong><tt>torch.randint(low,high,size)</tt></strong></a> devuelve enteros aleatorios desde low (incluido) hasta high (excluido)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDqxqLsNlmyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559e0573-e567-481a-df6a-4b7a68e97476"
      },
      "source": [
        "x = torch.rand(4, 3)\n",
        "print(x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.3623e-01, 5.8966e-02, 4.8576e-01],\n",
            "        [8.3939e-01, 1.7701e-01, 2.0069e-01],\n",
            "        [3.4136e-01, 8.8924e-01, 9.0969e-04],\n",
            "        [9.3806e-01, 5.6992e-01, 2.1040e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VNc2vQylmyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc31c987-6c88-4c63-c43f-5addcc8a589c"
      },
      "source": [
        "x = torch.randn(4, 3)\n",
        "print(x)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.7482,  0.3573,  0.4945],\n",
            "        [ 1.1479, -0.5313, -0.1964],\n",
            "        [-1.0566, -0.4809,  0.1809],\n",
            "        [ 1.4129,  0.6857, -1.7714]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfYy0uJplmyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cddd6ce-0d40-4b17-98a5-bc22e6907a7a"
      },
      "source": [
        "x = torch.randint(0, 5, (4, 3))\n",
        "print(x)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 3, 4],\n",
            "        [4, 3, 1],\n",
            "        [2, 2, 4],\n",
            "        [3, 4, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2_Ck2TClmyR"
      },
      "source": [
        "### Tensores de números aleatorios que toman un tamaño de entrada (input size)\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.rand_like'><strong><tt>torch.rand_like(input)</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.randn_like'><strong><tt>torch.randn_like(input)</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.randint_like'><strong><tt>torch.randint_like(input,low,high)</tt></strong></a><br> Estos métodos retornan tensores con números aleatorios con las mismas dimensiones que <tt>input</tt>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWpiBHhhlmyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72987ab8-f6d8-4a7e-df40-81e36d998537"
      },
      "source": [
        "x = torch.zeros(2,5)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q125f1nplmyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947c1529-2aec-4842-e8b1-02452a4a9440"
      },
      "source": [
        "x2 = torch.randn_like(x)\n",
        "print(x2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6135,  1.6530, -0.9548, -0.8466,  1.0128],\n",
            "        [ 1.1074,  1.1732,  0.4247,  0.6938,  0.5924]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuwZ6BqPlmyT"
      },
      "source": [
        "La misma sintáxis puede ser empleada con<br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.zeros_like'><strong><tt>torch.zeros_like(input)</tt></strong></a><br>\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.ones_like'><strong><tt>torch.ones_like(input)</tt></strong></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XP_qivLlmyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ea224e-c078-48c8-dfc6-44494f7fa730"
      },
      "source": [
        "x3 = torch.ones_like(x2)\n",
        "print(x3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okgqGPiTlmyU"
      },
      "source": [
        "### Estableciendo una semilla (seed) aleatoria\n",
        "<a href='https://pytorch.org/docs/stable/torch.html#torch.manual_seed'><strong><tt>torch.manual_seed(int)</tt></strong></a> es empleado para obtener resultados reproducibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3yP1eiKlmyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628afa2b-cba1-4a9f-f95c-d6980b4b5f38"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "x = torch.rand(2, 3)\n",
        "print(x)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpyaOXurlmyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fafdf7ee-44ed-4721-8d4c-218c9189630f"
      },
      "source": [
        "torch.manual_seed(4)\n",
        "x = torch.rand(2, 3)\n",
        "print(x)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5596, 0.5591, 0.0915],\n",
            "        [0.2100, 0.0072, 0.0390]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1if2_GfdlmyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c05c12f-700e-4db3-8a32-8d18ea5daee9"
      },
      "source": [
        "x = torch.rand(2, 3)\n",
        "print(x)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9929, 0.9131, 0.6186],\n",
            "        [0.9744, 0.3189, 0.2148]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scEZVvw8lmyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f059d28-0930-4ca3-87a0-bf33baa5441d"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "x = torch.rand(2, 3)\n",
        "print(x)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829],\n",
            "        [0.9593, 0.3904, 0.6009]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUHjaEv2lmyZ"
      },
      "source": [
        "## Atributos de los tensores\n",
        "Además <tt>dtype</tt>, podemos obtener otros <a href='https://pytorch.org/docs/stable/tensor_attributes.html'>atributos de tensores</a> como <tt>shape</tt>, <tt>device</tt> and <tt>layout</tt>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTkUoFvqlmya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210deaea-f91b-4df7-bf3d-98528a7dd679"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmLtn144lmya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4f2b3e-0505-41b0-fa43-0e4450aeebb5"
      },
      "source": [
        "x.size()  # equivalente a x.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exi9Abq2lmyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4eec42-6dc1-4b65-dc52-3d2c99766ad3"
      },
      "source": [
        "x.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNmte7Islmyc"
      },
      "source": [
        "PyTorch soporta el uso de múltiples <a href='https://pytorch.org/docs/stable/tensor_attributes.html#torch-device'>devices</a>, beneficiandose de la potencia de una o más GPUs en lugar de una CPU.<br>\n",
        "No vamos a explorar eso en este notebook, pero es importante saber que esas operaciones entre tensores solo pueden tener lugar si los tensores estan alojados en la memoria del mismo dispositivo (device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T6oGAXmClmyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42063e2-b332-4dc4-fc21-40889ed6d00e"
      },
      "source": [
        "x.layout"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.strided"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtFAVgUAlmyd"
      },
      "source": [
        "PyTorch tiene una clase para contener las opciones de disposicion de memoria o  <a href='https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.layout'>memory layout</a>. La configuración por defecto es <a href='https://en.wikipedia.org/wiki/Stride_of_an_array'>strided</a> y en principio es la que vamos a emplear en estas sesiones. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pWx_dGzIltTx"
      },
      "source": [
        "# Operaciones con tensores \n",
        "* Indexado y subselección\n",
        "* Redimensionado de tensores ( vistas de tensores)\n",
        "* Aritmética y operaciones matemáticas con tensores\n",
        "* Productos\n",
        "* Multiplicacion de matrices \n",
        "* Y más operaciones...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEQxZ4qLltTz"
      },
      "source": [
        "## Indexado y subselección (slicing)\n",
        "Extraer valores específicos de un tensor funciona igual que con los arrays de Numpy<br>\n",
        "\n",
        "\n",
        "![Indexing](https://imgur.com/DDsVVeE.png)\n",
        "\n",
        "Fuente de imagen: http://www.scipy-lectures.org/_images/numpy_indexing.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Woo2I20AltTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd69b60-f06c-4cb9-cc92-545fd17ee22a"
      },
      "source": [
        "x = torch.arange(6).reshape(3,2)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azd6gdZnltT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf637435-d054-4c16-f6da-4bb4ff8c247a"
      },
      "source": [
        "# Accediendo a la columna de la derecha\n",
        "x[:,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7HckuO0ltT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611d5b28-7df8-4109-aad6-fcdeb727d894"
      },
      "source": [
        "# Accediendo a la columna de la derecha, como una \"rebanada\" (3,1), i.e. manteniendo el formato original del array.\n",
        "x[:,1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [3],\n",
              "        [5]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mccQ3x4AltT2"
      },
      "source": [
        "## Redimensionando tensores con <tt>.view()</tt>\n",
        "<a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view'><strong><tt>view()</tt></strong></a> y <a href='https://pytorch.org/docs/master/torch.html#torch.reshape'><strong><tt>reshape()</tt></strong></a> hacen esencialmente lo mismo, retornan un tensor redimensionado sin cambiar el tensor original en cuestion. <br>\n",
        "Las diferencias se pueden revisar con más detalle <a href='https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch'>aquí</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcOq8EfoltT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5cf3973-2834-4f99-d175-99a71e050ffe"
      },
      "source": [
        "x = torch.arange(10)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxHH-eEiltT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ea5f64-ba63-4d6d-ee6e-c922baf5fa5f"
      },
      "source": [
        "x.view(2,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2, 3, 4],\n",
              "        [5, 6, 7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTkUgUwLltT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff554fb3-fc7d-4baa-c306-f11416bbaa4c"
      },
      "source": [
        "x.view(5,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5],\n",
              "        [6, 7],\n",
              "        [8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PXzNtIlltT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36edfefe-fa81-47fb-fefb-a1adcf4d6a6a"
      },
      "source": [
        "# x no ha cambiado su forma\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIwfhJw_ltT5"
      },
      "source": [
        "### View refleja los datos actualizados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Il7069UltT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2550a2-236b-46eb-e36f-c6a0fb825caa"
      },
      "source": [
        "z = x.view(2,5)\n",
        "x[0]=234\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[234,   1,   2,   3,   4],\n",
            "        [  5,   6,   7,   8,   9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecCw8R6wxTrW",
        "outputId": "0a379366-44b2-4a18-eb12-5fa0c178ae2e"
      },
      "source": [
        "z[0,0] = 12\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[12,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akhc99YCxvcJ",
        "outputId": "d8efe68f-9d04-4b81-fec4-5cf4a4e645da"
      },
      "source": [
        "print(x) # Los cambios en z afectan a x (es solo una \"vista\" de x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([12,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-F6rBQ7ltT6"
      },
      "source": [
        "### Las vistas pueden inferir el tamaño \n",
        "Pasando el valor <tt>-1</tt> PyTorch inferirá el valor correcto para el tensor dado<br> \n",
        "(Inferir es obtener el número de la dimensión automáticamente)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ex7VtVJltT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf186a9-9775-4786-c200-c6f793936475"
      },
      "source": [
        "x.view(2,-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12,  1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rPT-879ltT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3ada19-8bf7-48e2-f707-d37214a25d04"
      },
      "source": [
        "x.view(-1,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12,  1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfgLliVWltT7"
      },
      "source": [
        "### Adoptar la forma de otro tensor con <tt>.view_as()</tt>\n",
        "<a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view_as'><strong><tt>view_as(input)</tt></strong></a> solo funcionará con tensores que tienen el mismo número de elementos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tU8Qp8TltT8",
        "outputId": "9dfb115a-5028-429f-a205-ecfce35f73ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.view_as(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12,  1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuTIHhDyltT8"
      },
      "source": [
        "## Aritmética de Tensores\n",
        "La suma de tensores se puede realizar de diferentes formas según el resultado que queramos.<br>\n",
        "Como una simple expresión:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgz3qsyDltT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2520e0f3-42e1-42a6-be0e-b59423ebc81a"
      },
      "source": [
        "a = torch.tensor([1.,2.,3.])\n",
        "b = torch.tensor([4.,5.,6.])\n",
        "print(a + b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PePC58TSltT9"
      },
      "source": [
        "Como argumentos que pasamos en una función de torch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjERhGNVltT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9336d04-3152-4437-f747-780eeb3abfa3"
      },
      "source": [
        "print(torch.add(a, b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVp5Qo4vltT-"
      },
      "source": [
        "A un tensor de salida que indicamos como argumento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNzoSb97ltT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793ba8ac-6ba2-4102-d611-b8e8fc7f1f31"
      },
      "source": [
        "result = torch.empty(3)\n",
        "torch.add(a, b, out=result)  # equivale a result=torch.add(a,b)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIxu1ljcltT_"
      },
      "source": [
        "Operando in situ sobre el tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEzHF40IltT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1327225f-6632-4fb9-c8f2-84afd419a169"
      },
      "source": [
        "a.add_(b)  # equivale a a=torch.add(a,b)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKpDI4K0ltUA"
      },
      "source": [
        "<div class=\"alert alert-info\"><strong>NOTA:</strong> Cualquier operación que modifica a un tensor in situ debe incluir como sufijo un guión bajo _.\n",
        "    <br>En el ejemplo: <tt>a.add_(b)</tt> modifica <tt>a</tt>.</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCLQCvBWltUA"
      },
      "source": [
        "### Operaciones Básicas para Tensores\n",
        "<table style=\"display: inline-block\">\n",
        "<caption style=\"text-align: center\"><strong>Arithmetic</strong></caption>\n",
        "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
        "<tr><td>a + b</td><td>a.add(b)</td><td>element wise addition</td></tr>\n",
        "<tr><td>a - b</td><td>a.sub(b)</td><td>subtraction</td></tr>\n",
        "<tr><td>a * b</td><td>a.mul(b)</td><td>multiplication</td></tr>\n",
        "<tr><td>a / b</td><td>a.div(b)</td><td>division</td></tr>\n",
        "<tr><td>a % b</td><td>a.fmod(b)</td><td>modulo (remainder after division)</td></tr>\n",
        "<tr><td>a<sup>b</sup></td><td>a.pow(b)</td><td>power</td></tr>\n",
        "<tr><td>&nbsp;</td><td></td><td></td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl29DawBltUB"
      },
      "source": [
        "<table style=\"display: inline-block\">\n",
        "<caption style=\"text-align: center\"><strong>Monomial Operations</strong></caption>\n",
        "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
        "<tr><td>|a|</td><td>torch.abs(a)</td><td>absolute value</td></tr>\n",
        "<tr><td>1/a</td><td>torch.reciprocal(a)</td><td>reciprocal</td></tr>\n",
        "<tr><td>$\\sqrt{a}$</td><td>torch.sqrt(a)</td><td>square root</td></tr>\n",
        "<tr><td>log(a)</td><td>torch.log(a)</td><td>natural log</td></tr>\n",
        "<tr><td>e<sup>a</sup></td><td>torch.exp(a)</td><td>exponential</td></tr>\n",
        "<tr><td>12.34  ==>  12.</td><td>torch.trunc(a)</td><td>truncated integer</td></tr>\n",
        "<tr><td>12.34  ==>  0.34</td><td>torch.frac(a)</td><td>fractional component</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNAzlJXVltUB"
      },
      "source": [
        "<table style=\"display: inline-block\">\n",
        "<caption style=\"text-align: center\"><strong>Trigonometry</strong></caption>\n",
        "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
        "<tr><td>sin(a)</td><td>torch.sin(a)</td><td>sine</td></tr>\n",
        "<tr><td>cos(a)</td><td>torch.sin(a)</td><td>cosine</td></tr>\n",
        "<tr><td>tan(a)</td><td>torch.sin(a)</td><td>tangent</td></tr>\n",
        "<tr><td>arcsin(a)</td><td>torch.asin(a)</td><td>arc sine</td></tr>\n",
        "<tr><td>arccos(a)</td><td>torch.acos(a)</td><td>arc cosine</td></tr>\n",
        "<tr><td>arctan(a)</td><td>torch.atan(a)</td><td>arc tangent</td></tr>\n",
        "<tr><td>sinh(a)</td><td>torch.sinh(a)</td><td>hyperbolic sine</td></tr>\n",
        "<tr><td>cosh(a)</td><td>torch.cosh(a)</td><td>hyperbolic cosine</td></tr>\n",
        "<tr><td>tanh(a)</td><td>torch.tanh(a)</td><td>hyperbolic tangent</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbKgb_R3ltUC"
      },
      "source": [
        "<table style=\"display: inline-block\">\n",
        "<caption style=\"text-align: center\"><strong>Summary Statistics</strong></caption>\n",
        "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
        "<tr><td>$\\sum a$</td><td>torch.sum(a)</td><td>sum</td></tr>\n",
        "<tr><td>$\\bar a$</td><td>torch.mean(a)</td><td>mean</td></tr>\n",
        "<tr><td>a<sub>max</sub></td><td>torch.max(a)</td><td>maximum</td></tr>\n",
        "<tr><td>a<sub>min</sub></td><td>torch.min(a)</td><td>minimum</td></tr>\n",
        "<tr><td colspan=\"3\">torch.max(a,b) returns a tensor of size a<br>containing the element wise max between a and b</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynqzm67dltUD"
      },
      "source": [
        "<div class=\"alert alert-info\"><strong>NOTA:</strong> Muchas operaciones aritméticas requieren valores flotantes. Aquellas que trabajan con enteros retornarán tensores de enteros.<br>\n",
        "Por ejemplo, <tt>torch.div(a,b)</tt> realizará una dicisión con redondeo (truncando el decimal) si empleamos tipo entero, y una división clásica si empleamos floats.</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9bj4403ltUD"
      },
      "source": [
        "#### Observemos diferentes formas de operaciones: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fbCT2PpltUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84717d7f-c8ea-46a0-8919-28f1aec18ae5"
      },
      "source": [
        "a = torch.tensor([1,2,3], dtype=torch.float)\n",
        "b = torch.tensor([4,5,6], dtype=torch.float)\n",
        "print(torch.add(a,b).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(21.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct4KsMgEltUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa061d4-3e2f-4739-d916-162409bd8792"
      },
      "source": [
        "a = torch.tensor([1,2,3], dtype=torch.float)\n",
        "b = torch.tensor([4,5,6], dtype=torch.float)\n",
        "print(sum(a + b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(21.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFbgMs4LltUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d2fd50-9c1a-4f42-ab3e-5723c30d2270"
      },
      "source": [
        "a = torch.tensor([1,2,3], dtype=torch.float)\n",
        "b = torch.tensor([4,5,6], dtype=torch.float)\n",
        "print(sum(a.add_(b)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(21.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LvVVgH6ltUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9790f6-2e58-4938-ccd4-9456994b0392"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 7., 9.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToaRDphMltUG"
      },
      "source": [
        "## Producto escalar (dot product)\n",
        "El producto escalar <a href='https://en.wikipedia.org/wiki/Dot_product'>dot product</a> es la suma de los productos de los correspondientes elementos de dos tensores 1D. Si los tensores son dos vectores, el producto escalar será:<br>\n",
        "\n",
        "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d & e & f \\end{bmatrix} = ad + be + cf$\n",
        "\n",
        "Si los tensores incluyen a un tensor columna, entonces el producto escalar será igual a la suma de del resultado de las matrices multiplicadas. Por eljemplo:<br>\n",
        "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d \\\\ e \\\\ f \\end{bmatrix} = ad + be + cf$<br><br>\n",
        "El producto escalar (Dot products) puede ser expresado como <a href='https://pytorch.org/docs/stable/torch.html#torch.dot'><strong><tt>torch.dot(a,b)</tt></strong></a> o `a.dot(b)` o `b.dot(a)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ve9_OrXAltUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265de9c7-39bf-471e-cb35-7db2348c5192"
      },
      "source": [
        "a = torch.tensor([1,2,3], dtype=torch.float)\n",
        "b = torch.tensor([4,5,6], dtype=torch.float)\n",
        "print(a.mul(b)) # para referencia\n",
        "print()\n",
        "print(a.dot(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4., 10., 18.])\n",
            "\n",
            "tensor(32.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB1_DSw7ltUI"
      },
      "source": [
        "<div class=\"alert alert-info\"><strong>NOTA:</strong> Hay una ligera diferencia entre <tt>torch.dot()</tt> y <tt>numpy.dot()</tt>. Mientras <tt>torch.dot()</tt> solo acepta argumentos de 1D y devuelve el producto escalar, <tt>numpy.dot()</tt> también acepta argumentos 2D y realiza una multiplicación de matrices.<br>Vemos la multiplicacin de matrices en Pytorch a continuación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i721jrEqltUI"
      },
      "source": [
        "## Multiplicación de matrices\n",
        "La multiplicación de matrices 2D <a href='https://en.wikipedia.org/wiki/Matrix_multiplication'>(Matrix multiplication)</a> es posible cuando el número de columnas en el tensor <strong><tt>A</tt></strong> es igual el número de filas del tensor <strong><tt>B</tt></strong>. En este caso el producto del tensor  <strong><tt>A</tt></strong> de dimensiones $(x,y)$ y el tensor <strong><tt>B</tt></strong> con dimensiones $(y,z)$ resulta en un tensor de tamaño $(x,z)$\n",
        "\n",
        "![MatrixMultiplication](https://i.imgur.com/2xdyiul.jpg)\n",
        "\n",
        "\n",
        "$\\begin{bmatrix} a & b & c \\\\\n",
        "d & e & f \\end{bmatrix} \\;\\times\\; \\begin{bmatrix} m & n \\\\ p & q \\\\ r & s \\end{bmatrix} = \\begin{bmatrix} (am+bp+cr) & (an+bq+cs) \\\\\n",
        "(dm+ep+fr) & (dn+eq+fs) \\end{bmatrix}$</div></div>\n",
        "\n",
        "<div style=\"clear:both\">Image source: <a href='https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg'>https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg</a></div>\n",
        "\n",
        "La multiplicación de matrices en Pytorch puede ser calculada empleando <a href='https://pytorch.org/docs/stable/torch.html#torch.mm'><strong><tt>torch.mm(a,b)</tt></strong></a> o `a.mm(b)` *o* `a @ b`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poRZgY8jltUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e5572e-0571-4955-ed7a-6f1771064bce"
      },
      "source": [
        "a = torch.tensor([[0,2,4],[1,3,5]], dtype=torch.float)\n",
        "b = torch.tensor([[6,7],[8,9],[10,11]], dtype=torch.float)\n",
        "\n",
        "print('a: ',a.size())\n",
        "print('b: ',b.size())\n",
        "print('a x b: ',torch.mm(a,b).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:  torch.Size([2, 3])\n",
            "b:  torch.Size([3, 2])\n",
            "a x b:  torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWspQWHEltUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4ac995-bbfc-486f-ac31-f0c86e6aa17f"
      },
      "source": [
        "print(torch.mm(a,b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[56., 62.],\n",
            "        [80., 89.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4igAkxOvltUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af91a92e-b9de-45f1-df7b-1a3adb7dd573"
      },
      "source": [
        "print(a.mm(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[56., 62.],\n",
            "        [80., 89.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlS2_i4cltUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f269cbf3-031d-48ba-99ef-1a349259355c"
      },
      "source": [
        "print(a @ b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[56., 62.],\n",
            "        [80., 89.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJIJEJqCltUK"
      },
      "source": [
        "### Multiplicación de matrices con broadcasting\n",
        "Multiplicación de matrices que implica <a href='https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics'>broadcasting</a> se puede realizar empleando <a href='https://pytorch.org/docs/stable/torch.html#torch.matmul'><strong><tt>torch.matmul(a,b)</tt></strong></a> o `a.matmul(b)` o `a @ b`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXkhC4_NltUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1579d3bf-b8de-42b2-fa84-3c7b0c3d6b49"
      },
      "source": [
        "t1 = torch.randn(2, 3, 4)\n",
        "t2 = torch.randn(4, 5)\n",
        "\n",
        "print(torch.matmul(t1, t2).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UsLLBJ-ltUL"
      },
      "source": [
        "Sin embargo, la misma operatión da <tt><strong>RuntimeError</strong></tt> con <tt>torch.mm()</tt>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UKLo8FrltUL",
        "outputId": "00603b93-50f1-498a-a858-a46c015053fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "print(torch.mm(t1, t2).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-edaac219da2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: self must be a matrix"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSlSQJlbltUM"
      },
      "source": [
        "___\n",
        "# Operaciones avanzadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXzB-rhEltUN"
      },
      "source": [
        "## L2 o norma Euclídea (distancia euclídea)\n",
        "Ver <a href='https://pytorch.org/docs/stable/torch.html#torch.norm'><strong><tt>torch.norm()</tt></strong></a>\n",
        "\n",
        "La <a href='https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm'>norma Euclídea</a> para el vector $x$ donde $x=(x_1,x_2,...,x_n)$ es calculada como <br>\n",
        "\n",
        "${\\displaystyle \\left\\|{\\boldsymbol {x}}\\right\\|_{2}:={\\sqrt {x_{1}^{2}+\\cdots +x_{n}^{2}}}}$\n",
        "\n",
        "\n",
        "Cuando se aplica a una matriz, <tt>torch.norm()</tt> retorna la norma matricial o <a href='https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm'>Frobenius norm</a> por defecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To__Yz5jltUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b36a98-0aae-4e6e-ae93-3e1e3664964c"
      },
      "source": [
        "x = torch.tensor([2.,5.,8.,14.])\n",
        "x.norm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvD50Nf_ltUN"
      },
      "source": [
        "## Número de elementos\n",
        "Ver <a href='https://pytorch.org/docs/stable/torch.html#torch.numel'><strong><tt>torch.numel()</tt></strong></a>\n",
        "\n",
        "Retorna el numero de elementos en un tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hls-47JfltUO",
        "outputId": "3569a683-3b35-472f-afcf-8b1d384a2651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(3,7)\n",
        "x.numel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-Wbp_VAltUO"
      },
      "source": [
        "Esto es espcialmente útil en ciertos cálculos como el error cuadrático medio ($Mean Squared Error$):<br>\n",
        "<tt>\n",
        "def mse(t1, t2):<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;diff = t1 - t2<br>\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;return torch.sum(diff * diff) / diff<strong>.numel()</strong></tt>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJnSCwuj_GE6"
      },
      "source": [
        "## Gradientes con tensores\n",
        "\n",
        "Podemos combinar tensores en las operaciones artiméticas habituales. Veamos un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ip8DUi_GE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2731a88d-362a-440b-d376-54ca723fe0ff"
      },
      "source": [
        "# Creamos tensores. Atención a los argumentos...\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "x, w, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY8ds-wN_GE7"
      },
      "source": [
        "Hemos creado tres tensores: `x`, `w`, and `b`, todos ellos números. `w` y `b` tienen un parámetro adicional `requires_grad` puesto a `True`. Veremos lo que hace en las siguientes celdas\n",
        "\n",
        "Vamos a crear un tensor `y` que combina dichos tensores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCCamx4k_GE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7839af-54be-47cd-afbb-a0981b0c3d32"
      },
      "source": [
        "y = w * x + b\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD2qOIi-_GE7"
      },
      "source": [
        "Como es de esperar, `y` es un tensor con el valor `3 * 4 + 5 = 17`. \n",
        "Lo que hace a Pytorch único es que **podemos calcular automáticamente** la derivada de `y` w.r.t. (con respecto a) los tensores que tienen configurado `requires_grad` a `True` en este caso w and b. Esta funcionalidad de PyTorch se llama _autograd_ (automatic gradients).\n",
        "\n",
        "Para calcular las derivadas, tenemos que invocar el método `.backward` en el resultado `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZYQstan_GE8"
      },
      "source": [
        "# Calcular derivadas\n",
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4v7zusU_GE8"
      },
      "source": [
        "Las derivadas de `y` con respecto a los tensores de entrada estan almacenadas en el atributo`.grad` de los respectivos tensores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe4VBmk4_GE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ee4884-291c-4de8-c108-d814a75f2902"
      },
      "source": [
        "# Mostrar gradientes\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsxsE7JP_GE9"
      },
      "source": [
        "Como era de esperar, `dy/dw` tiene el mismo valor que `x`, i.e., `3`, y `dy/db` tiene el valor `1`. Observa que `x.grad` es `None` porque `x` no tiene `requires_grad` puesto a `True`. <br> \n",
        "El nombre  \"grad\" en `w.grad` es una abreviatura para _gradient_, que es otra denominación de la derivada. El término _gradient_ es principalmente usado cuaddo se trabaja con vectores y matrices y es especialmente útil en la computación de redes neuronales. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2QOf-HEltUP"
      },
      "source": [
        "## Fin del Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDr1zYmBkRV"
      },
      "source": [
        "Referencias y modelos empleados para el Notebook: \n",
        "\n",
        "*   Documentación de [Pytorch](https://pytorch.org/docs/stable/index.html) \n",
        "*   [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi\n",
        "*   [FastAI](https://www.fast.ai/) development notebooks by Jeremy Howard.\n",
        "*   Documentación y cursos en [Pierian Data](https://www.pieriandata.com/)\n"
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoniaPMi/AI-3-PyTorch/blob/main/Dinosaur_names_generator_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSvaD0lMAtQu"
      },
      "source": [
        "# Dinosaur names generator using LSTMs\n",
        "\n",
        "La idea es aprender nombres de dinosaurios y poder generar uno plausible dando una letra inicial como semilla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zExspKMnAmeV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import random\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.functional import F\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxzOWzAZA6-t",
        "outputId": "86445b86-5049-414d-b4fd-f9df71351687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's', '<EOS>']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1545"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Create sequences of chars, end all sequences with special char \"<EOS>\"\n",
        "def split_to_names(fname):\n",
        "  # COMPLETAR Cargar fichero, dividir cada nombre de dinosaurio en sus caracteres y agregar el caracter\n",
        "  # End of Sequence ('<EOS>') al final. Guardar cada lista de caracteres como elemento de otra lista. \n",
        "  # El resultado a devolver es la lista de listas obtenida.\n",
        "  EOS = \"<EOS>\"\n",
        "  data = []\n",
        "\n",
        "  with open(fname) as file:\n",
        "    text = file.read().lower()\n",
        "\n",
        "  names = text.splitlines()\n",
        "  for i, name in enumerate(names):\n",
        "    ch_list = list(name) + [EOS]\n",
        "    data.append(ch_list)\n",
        "  return data\n",
        "\n",
        "data_in_char = split_to_names(\"./dinos.txt\")\n",
        "\n",
        "#test\n",
        "print(data_in_char[0])\n",
        "len(data_in_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "ILiKLvoVRbNX",
        "outputId": "2af9e72a-0ede-441d-f0bd-901450b85c89"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-a893748edaf2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    char_vocab = # COMPLETAR\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "char_vocab = [\"<EOS>\"] + sorted([ch for ch in string.ascii_lowercase])\n",
        "print(char_vocab)\n",
        "char_to_ix = {ch:i for i,ch in enumerates}\n",
        "ix_to_char = #COMPLETAR\n",
        "\n",
        "def keys_to_values(keys, char_to_ix_dict):\n",
        "    return #COMPLETAR\n",
        "# test\n",
        "keys_to_values('k',char_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwTIzIVGtfpM"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_as_str, char_to_ix_dict):\n",
        "        self.data_as_int = [] #Lista que alojará el dataset convertido a enteros\n",
        "        \n",
        "        # COMPLETAR: Convert characters to integers for each sequence in the list\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return #COMPLETAR\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        # Get data sample at index ix\n",
        "        item = self.data_as_int[ix]\n",
        "        # Slice x and y from sample\n",
        "        x = item[#COMPLETAR]\n",
        "        y = item[#COMPLETAR]\n",
        "        return #COMPLETAR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPLV9D67C_P4"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(#COMPLETAR)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP4eqrnWvl9O",
        "outputId": "d45cee39-dd1d-42ac-a615-2d9ee29e8015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([ 1,  1,  3,  8,  5, 14, 15, 19,  1, 21, 18, 21, 19]), tensor([ 1,  3,  8,  5, 14, 15, 19,  1, 21, 18, 21, 19,  0]))\n",
            "1545\n"
          ]
        }
      ],
      "source": [
        "#test\n",
        "print(dataset[0])\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm6y4XMqwUMc"
      },
      "outputs": [],
      "source": [
        "#COMPLETAR modelo. Ver el print de debajo para obtener los parámteros\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, char_to_ix_dict):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.vocab_size  = len(char_to_ix_dict)\n",
        "        self.hidden_size = # COMPLETAR\n",
        "        self.emb_dim     = # COMPLETAR\n",
        "        self.n_layers    = # COMPLETAR\n",
        "        self.dropout_p   = # COMPLETAR\n",
        "        \n",
        "        self.embedding = nn.Embedding(\n",
        "            #COMPLETAR)\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            #COMPLETAR)\n",
        "        \n",
        "        self.dropout = nn.Dropout(#COMPLETAR)\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            #COMPLETAR)\n",
        "        \n",
        "    def forward(self, x, prev_state):\n",
        "        #COMPLETAR\n",
        "    \n",
        "    def init_state(self, b_size=1):\n",
        "        #COMPLETAR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRUTlXutDYEC",
        "outputId": "307b9c69-2cca-4a59-b970-e264fc688173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (embedding): Embedding(27, 8)\n",
            "  (lstm): LSTM(8, 64, batch_first=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=64, out_features=27, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = #COMPLETAR\n",
        "print(model) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ6IKX5VDoYq",
        "outputId": "1bc398c4-f952-4e57-bce3-8c03f3bbe099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000/50000, Loss:   2.2623\n",
            "Epoch: 2000/50000, Loss:   1.9410\n",
            "Epoch: 3000/50000, Loss:   1.8248\n",
            "Epoch: 4000/50000, Loss:   1.7441\n",
            "Epoch: 5000/50000, Loss:   1.7167\n",
            "Epoch: 6000/50000, Loss:   1.6962\n",
            "Epoch: 7000/50000, Loss:   1.6648\n",
            "Epoch: 8000/50000, Loss:   1.6051\n",
            "Epoch: 9000/50000, Loss:   1.6171\n",
            "Epoch: 10000/50000, Loss:   1.5886\n",
            "Epoch: 11000/50000, Loss:   1.5541\n",
            "Epoch: 12000/50000, Loss:   1.5426\n",
            "Epoch: 13000/50000, Loss:   1.5471\n",
            "Epoch: 14000/50000, Loss:   1.5047\n",
            "Epoch: 15000/50000, Loss:   1.4972\n",
            "Epoch: 16000/50000, Loss:   1.4695\n",
            "Epoch: 17000/50000, Loss:   1.4796\n",
            "Epoch: 18000/50000, Loss:   1.4509\n",
            "Epoch: 19000/50000, Loss:   1.4464\n",
            "Epoch: 20000/50000, Loss:   1.4317\n",
            "Epoch: 21000/50000, Loss:   1.4259\n",
            "Epoch: 22000/50000, Loss:   1.4057\n",
            "Epoch: 23000/50000, Loss:   1.4039\n",
            "Epoch: 24000/50000, Loss:   1.3751\n",
            "Epoch: 25000/50000, Loss:   1.3807\n",
            "Epoch: 26000/50000, Loss:   1.3482\n",
            "Epoch: 27000/50000, Loss:   1.3510\n",
            "Epoch: 28000/50000, Loss:   1.3605\n",
            "Epoch: 29000/50000, Loss:   1.3188\n",
            "Epoch: 30000/50000, Loss:   1.3412\n",
            "Epoch: 31000/50000, Loss:   1.3371\n",
            "Epoch: 32000/50000, Loss:   1.2989\n",
            "Epoch: 33000/50000, Loss:   1.2848\n",
            "Epoch: 34000/50000, Loss:   1.3186\n",
            "Epoch: 35000/50000, Loss:   1.2906\n",
            "Epoch: 36000/50000, Loss:   1.2476\n",
            "Epoch: 37000/50000, Loss:   1.2922\n",
            "Epoch: 38000/50000, Loss:   1.2549\n",
            "Epoch: 39000/50000, Loss:   1.2597\n",
            "Epoch: 40000/50000, Loss:   1.2595\n",
            "Epoch: 41000/50000, Loss:   1.2573\n",
            "Epoch: 42000/50000, Loss:   1.2078\n",
            "Epoch: 43000/50000, Loss:   1.2299\n",
            "Epoch: 44000/50000, Loss:   1.2063\n",
            "Epoch: 45000/50000, Loss:   1.2230\n",
            "Epoch: 46000/50000, Loss:   1.2002\n",
            "Epoch: 47000/50000, Loss:   1.1901\n",
            "Epoch: 48000/50000, Loss:   1.2182\n",
            "Epoch: 49000/50000, Loss:   1.1909\n",
            "Epoch: 50000/50000, Loss:   1.1846\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "    \n",
        "loss_list = []\n",
        "running_loss = 0\n",
        "optimizer = #COMPLETAR\n",
        "criterion = #COMPLETAR\n",
        "num_epochs=#COMPLETAR\n",
        "\n",
        "epoch=1\n",
        "while(epoch<num_epochs):\n",
        "  for x, y in dataloader:\n",
        "    \n",
        "    #COMPLETAR\n",
        "\n",
        "    epoch+=1\n",
        "\n",
        "    if epoch%1000==0:\n",
        "      print(\"Epoch: {}/{}, Loss: {:8.4f}\".format(\n",
        "          epoch, num_epochs, running_loss/1000))\n",
        "      running_loss = 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTmPBHROGaIa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample_next(model, x, prev_state, topk=5, uniform=True):\n",
        "    # Perform forward-prop and get the output of the last time-step\n",
        "    out, state = model(x, prev_state)\n",
        "    last_out = out[0, -1, :]\n",
        "\n",
        "    # Get the top-k indexes and their values\n",
        "    topk = topk if topk else last_out.shape[0]\n",
        "    top_logit, top_ix = torch.topk(last_out, k=topk, dim=-1)\n",
        "    \n",
        "    # Get the softmax of the topk's and sample\n",
        "    p = None if uniform else F.softmax(top_logit.detach(), dim=-1).numpy()\n",
        "    sampled_ix = np.random.choice(top_ix, p=p)\n",
        "    return sampled_ix, state\n",
        "\n",
        "\n",
        "def sample(model, seed, topk=5, uniform=True, max_seqlen=18, stop_on=None):\n",
        "    seed = seed if isinstance(seed, (list, tuple)) else [seed]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        sampled_ix_list = seed[:]\n",
        "        x = torch.tensor([seed])\n",
        "        \n",
        "        prev_state = model.init_state(b_size=1)\n",
        "        for t in range(max_seqlen - len(seed)):\n",
        "            sampled_ix, prev_state = sample_next(model, x, prev_state, topk, uniform)\n",
        "\n",
        "            sampled_ix_list.append(sampled_ix)\n",
        "            x = torch.tensor([[sampled_ix]])\n",
        "            \n",
        "            if sampled_ix==stop_on:\n",
        "                break\n",
        "    \n",
        "    model.train()\n",
        "    return sampled_ix_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CSdT9DQGqHS",
        "outputId": "28d58fa8-e993-4894-9e94-1738c66bb0fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Samples where seed is a randomly chosen character.\n",
            "i => inornis<EOS>\n",
            "a => amalilong<EOS>\n",
            "f => fulusunasaurus<EOS>\n",
            "z => zingobaria<EOS>\n",
            "r => rachytitanes<EOS>\n",
            "t => teratosaurus<EOS>\n",
            "d => diceratoptes<EOS>\n",
            "j => jiamsaurus<EOS>\n",
            "s => styratosaurus<EOS>\n",
            "h => hypselosaurus<EOS>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Samples where seed is a randomly chosen character.\")\n",
        "# COMPLETAR llamando a sample(), para obtener 10 nombres de dinosaurios partiendo de una seed aleatoria  \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwxkSU3iVtjJ"
      },
      "outputs": [],
      "source": [
        "#COMPLETAR: Nombres de dinosaurios a partir de una secuencia de letras (Ej. tu nombre)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Dinosaur_names_generator_Pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}